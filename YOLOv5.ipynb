{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74e7d60-4597-46aa-9aca-b0c7cef96031",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qr https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt  # install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def6773f-6379-4210-a26c-382d8573e993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/cmt/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-4-1 Python-3.10.9 torch-1.12.0+cu102 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "%pylab inline \n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "from sort import *\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab957ae1-c8d0-4339-85d2-3090c2a0b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.eval()\n",
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854d8579-e0b4-430e-8012-00d37b13e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=416\n",
    "conf_thres=0.8\n",
    "nms_thres=0.4\n",
    "def detect_image(img):\n",
    "    # scale and pad image\n",
    "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
    "    imw = round(img.size[0] * ratio)\n",
    "    imh = round(img.size[1] * ratio)\n",
    "    img_transforms = transforms.Compose([ transforms.Resize((imh, imw)),\n",
    "         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n",
    "                        (128,128,128)),\n",
    "         transforms.ToTensor(),\n",
    "         ])\n",
    "    # convert image to Tensor\n",
    "    image_tensor = img_transforms(img).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0).to(device)\n",
    "    #input_img = Variable(image_tensor.type(Tensor))\n",
    "    # run inference on the model and get detections\n",
    "    with torch.no_grad():\n",
    "        detections = model(image_tensor)\n",
    "        #detections = utils.non_max_suppression(detections, 80, conf_thres, nms_thres)\n",
    "    return detections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154a0755-dbaa-47cc-8b73-a7285ee3beda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame  643\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "videopath = 'etc/vidroom2.mp4'\n",
    "\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('tab20b')\n",
    "colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "# initialize Sort object and video capture\n",
    "vid = cv2.VideoCapture(videopath)\n",
    "mot_tracker = Sort() \n",
    "\n",
    "# Save output to avi video\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "fps = 25.0\n",
    "width = 1080\n",
    "height = 1920\n",
    "out = cv2.VideoWriter(\"output.avi\", fourcc, fps, (width, height))\n",
    "\n",
    "#while(True):\n",
    "counter = 0\n",
    "while vid.isOpened():\n",
    "    print(\"Frame \", counter)\n",
    "    ret, frame = vid.read()\n",
    "    if frame is None:\n",
    "        print('Finished!')\n",
    "        out.release()\n",
    "        break\n",
    "    counter += 1\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.flip(frame, 0)\n",
    "    pilimg = Image.fromarray(frame)\n",
    "    detections = model(frame)\n",
    "    #print(\"N det: \", len(detections.pandas().xyxy[0]))\n",
    "\n",
    "    img = np.array(pilimg)\n",
    "    pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
    "    pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
    "    unpad_h = img_size - pad_y\n",
    "    unpad_w = img_size - pad_x\n",
    "    #detections.render()  # updates results.ims with boxes and labels\n",
    "    #for im in detections.ims:\n",
    "    #    buffered = BytesIO()\n",
    "    #    im_base64 = Image.fromarray(im)\n",
    "    #frame = cv2.cvtColor(numpy.array(im_base64), cv2.COLOR_RGB2BGR)\n",
    "    if detections is not None:\n",
    "        print(\"N det: \", len(detections.pandas().xyxy[0]))\n",
    "        tracked_objects = mot_tracker.update(detections.pandas().xyxy[0].iloc[:,:5].to_numpy())\n",
    "        print(\"N tracked: \", len(tracked_objects))\n",
    "\n",
    "        for x1, y1, x2, y2, obj_id in tracked_objects:\n",
    "            #x1, y1, x2, y2, obj_id = float(x1), float(y1), float(x2), float(y2), int(obj_id)\n",
    "            #box_h = int(((y2 - y1) / unpad_h) * img.shape[0])\n",
    "            #box_w = int(((x2 - x1) / unpad_w) * img.shape[1])\n",
    "            #y1 = int(((y1 - pad_y // 2) / unpad_h) * img.shape[0])\n",
    "            #x1 = int(((x1 - pad_x // 2) / unpad_w) * img.shape[1])\n",
    "\n",
    "            color = colors[int(obj_id) % len(colors)]\n",
    "            color = [i * 255 for i in color]\n",
    "            #cv2.rectangle(frame, (x1, y1), (x1+box_w, y1+box_h), color, 4)\n",
    "            #cv2.rectangle(frame, (x1, y1-35), (x1+len(str(obj_id))*19+60, y1), color, -1)\n",
    "            #cv2.putText(frame, str(obj_id), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n",
    "            \n",
    "            # Draw the bounding box around the tracked object\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 3)\n",
    "            # Save the detections to the video file\n",
    "            #out.write(frame)\n",
    "    out.write(frame)\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6216198-db92-4b19-81f3-0bdef671c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.034546</td>\n",
       "      <td>566.277893</td>\n",
       "      <td>1918.727417</td>\n",
       "      <td>0.864846</td>\n",
       "      <td>56</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650.831665</td>\n",
       "      <td>732.959229</td>\n",
       "      <td>878.007202</td>\n",
       "      <td>1035.481445</td>\n",
       "      <td>0.843067</td>\n",
       "      <td>58</td>\n",
       "      <td>potted plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.568062</td>\n",
       "      <td>645.281128</td>\n",
       "      <td>206.257294</td>\n",
       "      <td>825.170349</td>\n",
       "      <td>0.694664</td>\n",
       "      <td>58</td>\n",
       "      <td>potted plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315.564728</td>\n",
       "      <td>182.156982</td>\n",
       "      <td>427.244690</td>\n",
       "      <td>407.752350</td>\n",
       "      <td>0.662951</td>\n",
       "      <td>39</td>\n",
       "      <td>bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199.963898</td>\n",
       "      <td>634.428406</td>\n",
       "      <td>304.374695</td>\n",
       "      <td>856.296814</td>\n",
       "      <td>0.656991</td>\n",
       "      <td>58</td>\n",
       "      <td>potted plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>271.127106</td>\n",
       "      <td>306.980347</td>\n",
       "      <td>322.899445</td>\n",
       "      <td>414.358429</td>\n",
       "      <td>0.580921</td>\n",
       "      <td>39</td>\n",
       "      <td>bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>391.976349</td>\n",
       "      <td>666.949158</td>\n",
       "      <td>666.850769</td>\n",
       "      <td>987.356018</td>\n",
       "      <td>0.574073</td>\n",
       "      <td>58</td>\n",
       "      <td>potted plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>310.032776</td>\n",
       "      <td>183.676102</td>\n",
       "      <td>423.452576</td>\n",
       "      <td>407.236389</td>\n",
       "      <td>0.548258</td>\n",
       "      <td>58</td>\n",
       "      <td>potted plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>276.248688</td>\n",
       "      <td>600.474976</td>\n",
       "      <td>533.053894</td>\n",
       "      <td>906.181458</td>\n",
       "      <td>0.516682</td>\n",
       "      <td>58</td>\n",
       "      <td>potted plant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xmin        ymin        xmax         ymax  confidence  class  \\\n",
       "0    0.000000  946.034546  566.277893  1918.727417    0.864846     56   \n",
       "1  650.831665  732.959229  878.007202  1035.481445    0.843067     58   \n",
       "2   78.568062  645.281128  206.257294   825.170349    0.694664     58   \n",
       "3  315.564728  182.156982  427.244690   407.752350    0.662951     39   \n",
       "4  199.963898  634.428406  304.374695   856.296814    0.656991     58   \n",
       "5  271.127106  306.980347  322.899445   414.358429    0.580921     39   \n",
       "6  391.976349  666.949158  666.850769   987.356018    0.574073     58   \n",
       "7  310.032776  183.676102  423.452576   407.236389    0.548258     58   \n",
       "8  276.248688  600.474976  533.053894   906.181458    0.516682     58   \n",
       "\n",
       "           name  \n",
       "0         chair  \n",
       "1  potted plant  \n",
       "2  potted plant  \n",
       "3        bottle  \n",
       "4  potted plant  \n",
       "5        bottle  \n",
       "6  potted plant  \n",
       "7  potted plant  \n",
       "8  potted plant  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections.pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0205df-96d8-4002-b510-803e63eda90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     269.68,      305.96,      322.98,      415.29,         294],\n",
       "       [     310.49,      183.46,      422.92,      407.45,         285],\n",
       "       [     310.55,      182.26,      425.52,      407.93,         272],\n",
       "       [     648.72,      731.91,      877.77,      1037.2,         260],\n",
       "       [     402.01,      673.63,      666.34,      988.21,         255],\n",
       "       [     280.05,      603.18,      524.87,      905.23,         246],\n",
       "       [     200.02,      636.69,      301.91,      855.23,         240],\n",
       "       [     78.075,      647.06,      202.96,      825.19,         236],\n",
       "       [    -2.3038,      941.42,      568.36,      1922.5,         221]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracked_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708e63fc-0679-4b78-9814-8cc6f9fb70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a360478-9b6d-42f7-b66d-8bfc60019913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
